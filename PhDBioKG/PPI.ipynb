{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4efe444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv torch_geometric -f https://data.pyg.org/whl/torch-1.13.0+cpu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a4b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a7735",
   "metadata": {},
   "source": [
    "## Protein-Protein Interaction (PPI) network from SNAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6d0c3",
   "metadata": {},
   "source": [
    "This is protein-protein interaction network that contains physical interactions between proteins that are experimentally documented in humans, such as metabolic enzyme-coupled interactions and signaling interactions. Nodes represent human proteins and edges represent physical interaction between proteins in a human cell. \n",
    "\n",
    "\n",
    "More information about the dataset can be found at [https://snap.stanford.edu/biodata/datasets/10000/10000-PP-Pathways.html](https://snap.stanford.edu/biodata/datasets/10000/10000-PP-Pathways.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90241a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "Data = open('data/PP-Pathways_ppi.edges', \"r\")\n",
    "#next(Data, None)  # skip the first line in the input file\n",
    "Graphtype = nx.DiGraph()\n",
    "\n",
    "G = nx.parse_edgelist(Data, delimiter=',', create_using=Graphtype,\n",
    "                      nodetype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d015ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "data = from_networkx(G, group_node_attrs = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59e37661",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x = torch.Tensor([[1] for _ in range(data.num_nodes)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d7416e",
   "metadata": {},
   "source": [
    "### Link Prediction setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a3918",
   "metadata": {},
   "source": [
    "#### Link split and negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd08bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform random link split\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "link_split = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "train_link, val_link, test_link = link_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4cd61b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 256765], num_nodes=21557, x=[21557, 1], edge_label=[513530], edge_label_index=[2, 513530])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca37377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_label : 1 for closed link, 0 for open link\n",
    "# edge_label_index: edge_index + negative_sampling edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2715e4",
   "metadata": {},
   "source": [
    "### GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c18837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0af76",
   "metadata": {},
   "source": [
    "We can re-use the same GNN model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15033028",
   "metadata": {},
   "source": [
    "<img src=\"../img/CoraGCNLinkPre.png\" alt=\"linkpred_gcn\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706a87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, Linear\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b010d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN4PPI(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567) #manual seed for reproducibility\n",
    "        \n",
    "        self.lin1 = Linear(data.num_features, 64) \n",
    "        self.lin2 = Linear(64, 32)\n",
    "        self.conv1 = GCNConv(32, 16) \n",
    "        self.conv2 = GCNConv(16, 2)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        #x : node feature matrix, edge_index : structure of the graph\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad981518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6545\n",
      "Epoch: 002, Loss: 0.8919\n",
      "Epoch: 003, Loss: 0.6087\n",
      "Epoch: 004, Loss: 0.6539\n",
      "Epoch: 005, Loss: 0.6717\n",
      "Epoch: 006, Loss: 0.6777\n",
      "Epoch: 007, Loss: 0.6802\n",
      "Epoch: 008, Loss: 0.6769\n",
      "Epoch: 009, Loss: 0.6684\n",
      "Epoch: 010, Loss: 0.6569\n",
      "Epoch: 011, Loss: 0.6367\n",
      "Epoch: 012, Loss: 0.6173\n",
      "Epoch: 013, Loss: 0.6144\n",
      "Epoch: 014, Loss: 0.6295\n",
      "Epoch: 015, Loss: 0.6310\n",
      "Epoch: 016, Loss: 0.6190\n",
      "Epoch: 017, Loss: 0.6131\n",
      "Epoch: 018, Loss: 0.6101\n",
      "Epoch: 019, Loss: 0.6138\n",
      "Epoch: 020, Loss: 0.6155\n",
      "Epoch: 021, Loss: 0.6153\n",
      "Epoch: 022, Loss: 0.6119\n",
      "Epoch: 023, Loss: 0.6092\n",
      "Epoch: 024, Loss: 0.6084\n",
      "Epoch: 025, Loss: 0.6046\n",
      "Epoch: 026, Loss: 0.6057\n",
      "Epoch: 027, Loss: 0.6044\n",
      "Epoch: 028, Loss: 0.6060\n",
      "Epoch: 029, Loss: 0.6083\n",
      "Epoch: 030, Loss: 0.6050\n",
      "Epoch: 031, Loss: 0.6013\n",
      "Epoch: 032, Loss: 0.6014\n",
      "Epoch: 033, Loss: 0.6015\n",
      "Epoch: 034, Loss: 0.6009\n",
      "Epoch: 035, Loss: 0.6000\n",
      "Epoch: 036, Loss: 0.6000\n",
      "Epoch: 037, Loss: 0.5974\n",
      "Epoch: 038, Loss: 0.5963\n",
      "Epoch: 039, Loss: 0.5953\n",
      "Epoch: 040, Loss: 0.5963\n",
      "Epoch: 041, Loss: 0.5941\n",
      "Epoch: 042, Loss: 0.5927\n",
      "Epoch: 043, Loss: 0.5920\n",
      "Epoch: 044, Loss: 0.5937\n",
      "Epoch: 045, Loss: 0.5921\n",
      "Epoch: 046, Loss: 0.5914\n",
      "Epoch: 047, Loss: 0.5910\n",
      "Epoch: 048, Loss: 0.5904\n",
      "Epoch: 049, Loss: 0.5911\n",
      "Epoch: 050, Loss: 0.5890\n",
      "Epoch: 051, Loss: 0.5895\n",
      "Epoch: 052, Loss: 0.5882\n",
      "Epoch: 053, Loss: 0.5875\n",
      "Epoch: 054, Loss: 0.5870\n",
      "Epoch: 055, Loss: 0.5858\n",
      "Epoch: 056, Loss: 0.5853\n",
      "Epoch: 057, Loss: 0.5858\n",
      "Epoch: 058, Loss: 0.5839\n",
      "Epoch: 059, Loss: 0.5849\n",
      "Epoch: 060, Loss: 0.5854\n",
      "Epoch: 061, Loss: 0.5852\n",
      "Epoch: 062, Loss: 0.5822\n",
      "Epoch: 063, Loss: 0.5835\n",
      "Epoch: 064, Loss: 0.5826\n",
      "Epoch: 065, Loss: 0.5816\n",
      "Epoch: 066, Loss: 0.5799\n",
      "Epoch: 067, Loss: 0.5830\n",
      "Epoch: 068, Loss: 0.5829\n",
      "Epoch: 069, Loss: 0.5818\n",
      "Epoch: 070, Loss: 0.5783\n",
      "Epoch: 071, Loss: 0.5789\n",
      "Epoch: 072, Loss: 0.5793\n",
      "Epoch: 073, Loss: 0.5800\n",
      "Epoch: 074, Loss: 0.5776\n",
      "Epoch: 075, Loss: 0.5797\n",
      "Epoch: 076, Loss: 0.5783\n",
      "Epoch: 077, Loss: 0.5800\n",
      "Epoch: 078, Loss: 0.5782\n",
      "Epoch: 079, Loss: 0.5778\n",
      "Epoch: 080, Loss: 0.5789\n",
      "Epoch: 081, Loss: 0.5773\n",
      "Epoch: 082, Loss: 0.5800\n",
      "Epoch: 083, Loss: 0.5768\n",
      "Epoch: 084, Loss: 0.5787\n",
      "Epoch: 085, Loss: 0.5787\n",
      "Epoch: 086, Loss: 0.5782\n",
      "Epoch: 087, Loss: 0.5787\n",
      "Epoch: 088, Loss: 0.5771\n",
      "Epoch: 089, Loss: 0.5748\n",
      "Epoch: 090, Loss: 0.5782\n",
      "Epoch: 091, Loss: 0.5754\n",
      "Epoch: 092, Loss: 0.5757\n",
      "Epoch: 093, Loss: 0.5747\n",
      "Epoch: 094, Loss: 0.5750\n",
      "Epoch: 095, Loss: 0.5752\n",
      "Epoch: 096, Loss: 0.5734\n",
      "Epoch: 097, Loss: 0.5745\n",
      "Epoch: 098, Loss: 0.5766\n",
      "Epoch: 099, Loss: 0.5747\n",
      "Epoch: 100, Loss: 0.5761\n"
     ]
    }
   ],
   "source": [
    "model = GCN4PPI()\n",
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion =  torch.nn.BCEWithLogitsLoss() #change loss function\n",
    "\n",
    "def train_linkpre():\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(train_link.x, train_link.edge_index)  # Perform a single forward pass.\n",
    "    \n",
    "    ### LINK PREDICTION ACTS HERE ###\n",
    "    \n",
    "    out_src = out[train_link.edge_label_index[0]] #embedding src nodes\n",
    "    out_dst = out[train_link.edge_label_index[1]] #embedding dst nodes\n",
    "    \n",
    "    # LINK EMBEDDING #\n",
    "    # 1 - Dot Product\n",
    "    out_sim = out_src * out_dst #dotproduct\n",
    "    pred = torch.sum(out_sim, dim=-1)\n",
    "    \n",
    "    # 2 - Concatenation + linear function\n",
    "    #out_sim = torch.cat([out_src, out_dst], dim=-1)\n",
    "    #pred = torch.sum(out_sim,dim=-1)\n",
    "    \n",
    "    \n",
    "    loss = criterion(pred, train_link.edge_label.type_as(pred))  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss\n",
    "\n",
    "def test_linkpre(test_link):\n",
    "    model.eval()\n",
    "    out = model(test_link.x, test_link.edge_index)\n",
    "    \n",
    "    ### LINK PREDICTION ACTS HERE ###\n",
    "    \n",
    "    out_src = out[test_link.edge_label_index[0]] #embedding src nodes\n",
    "    out_dst = out[test_link.edge_label_index[1]] #embedding dst nodes\n",
    "    \n",
    "    # LINK EMBEDDING #\n",
    "    # 1 - Dot Product\n",
    "    out_sim = out_src * out_dst\n",
    "    h = torch.sum(out_sim, dim=-1)\n",
    "    \n",
    "    # 2 - Concatenation + linear function\n",
    "    #out_sim = torch.cat([out_src, out_dst], dim=-1)\n",
    "    #h = torch.sum(out_sim,dim=-1)\n",
    "    \n",
    "    pred_cont = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    \n",
    "    # EVALUATION\n",
    "    test_label = test_link.edge_label.cpu().detach().numpy() #retrieve test set labels\n",
    "    test_roc_score = roc_auc_score(test_label, pred_cont) #comput AUROC score for test set\n",
    "    \n",
    "    return test_roc_score\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train_linkpre()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73773cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUROC: 0.8578\n",
      "Test AUROC: 0.8570\n"
     ]
    }
   ],
   "source": [
    "roc_train = test_linkpre(train_link)\n",
    "roc_test = test_linkpre(test_link)\n",
    "print(f'Train AUROC: {roc_train:.4f}\\nTest AUROC: {roc_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66923a51",
   "metadata": {},
   "source": [
    "### Exercise 3 - HadamardMLP\n",
    "Actually, there are two popular solutions to perform the decoder step of link prediction tasks: the dot product and the HadamardMLP architecture. After theoretical and empirical analysis, [Wang et al. (2022)](https://arxiv.org/abs/2209.10100) find that the HadamardMLP decoders are generally more effective for LP.  \n",
    "\n",
    "Implement the HadamardMLP decoder into the CoraGCN architecture. The HadamardMLP consists of two steps:\n",
    "- Perform the hadamard product between the embeddings of nodes src and the embeddings of nodes dst.\n",
    "- Use a MLP layer to post-process the hadamard product.  \n",
    "\n",
    "Note that, for this task, you need to create a CoraGCNLP class that returns link prediction scores as the output of the forward method. Only in this way, the MLP layer parameters can be updated through the backpropagation steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
