{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4efe444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv torch_geometric -f https://data.pyg.org/whl/torch-1.13.0+cpu.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a7735",
   "metadata": {},
   "source": [
    "## Cora citation network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6d0c3",
   "metadata": {},
   "source": [
    "To demonstrate, we make use of the `Cora` dataset, which is a **citation network** where nodes represent documents.\n",
    "Each node is described by a 1433-dimensional bag-of-words feature vector.\n",
    "Two documents are connected if there exists a citation link between them.  \n",
    "The task are:\n",
    "- Node classification: to infer the category of each document (7 in total).\n",
    "- Link prediction: to predict missing citations between documents.\n",
    "\n",
    "This dataset was first introduced by [Yang et al. (2016)](https://arxiv.org/abs/1603.08861) as one of the datasets of the `Planetoid` benchmark suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76906d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='../data/Planetoid', name='Cora')\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e767381",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f8328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x : node feature matrix [#num_nodes, #num_features] \n",
    "# edge_index :  [#nodes_in_edge, #num_edges] e.g [[1,2],[3,4]] => (1,3), (2,4) in E\n",
    "# y : labels\n",
    "# train_mask, val_mask, test_mask : bit mask1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02af373",
   "metadata": {},
   "source": [
    "Data fields are not fixed, you can add/delete fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10f9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.z = torch.Tensor(np.array([0 for i in range(len(data.x))]))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360bb9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(data.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c30dde",
   "metadata": {},
   "source": [
    "We delete masks to perform custom nodes split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212184ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(data.train_mask)\n",
    "del(data.val_mask)\n",
    "del(data.test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63155157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Normalize features\n",
    "\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "transform = NormalizeFeatures() #Row-normalizes the attributes to sum-up to one\n",
    "data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Random Node Split\n",
    "\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "split = RandomNodeSplit(num_val=0.0,num_test=0.30)\n",
    "data = split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624c494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "print(f'Training set rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Validation set rate: {int(data.val_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Test set rate: {int(data.test_mask.sum()) / data.num_nodes:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456287be",
   "metadata": {},
   "source": [
    "## Load your own dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c7dd0a",
   "metadata": {},
   "source": [
    "Many options...  \n",
    "My favourite is use `from\\_networkx` util "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90241a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "mouse = nx.read_edgelist('../data/bn-mouse-kasthuri_graph_v4.edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1959af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do everything you can on networkx (add attributes, compute features, remove self-loops / isolated nodes, ...)\n",
    "\n",
    "#Example: add degree as node feature\n",
    "deg = dict(mouse.degree())\n",
    "nx.set_node_attributes(mouse,deg,'degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d015ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "mouse_data = from_networkx(mouse, group_node_attrs = all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e37661",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8eecd1",
   "metadata": {},
   "source": [
    "#### No feature? No problem! Constant encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef467b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import Constant\n",
    "\n",
    "constant = Constant(cat=False) #cat = False drop the other features\n",
    "mouse_data = constant(mouse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1452e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_data.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c9c0c1",
   "metadata": {},
   "source": [
    "#### Create your own dataset in PyG: https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32137d68",
   "metadata": {},
   "source": [
    "## Node2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1d796",
   "metadata": {},
   "source": [
    "Let's see together the example available on pyg repository: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/node2vec.py . To understand its parameters you can refer to: https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.Node2Vec.html#torch_geometric.nn.models.Node2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4300685a",
   "metadata": {},
   "source": [
    "## GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, Linear\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b010d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoraGCN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567) #manual seed for reproducibility\n",
    "        \n",
    "        self.lin1 = Linear(dataset.num_features, 64) \n",
    "        self.lin2 = Linear(64, 32) #two MLP layers to preprocess the BoW\n",
    "        self.conv1 = GCNConv(32, 16) \n",
    "        self.conv2 = GCNConv(16, dataset.num_classes) #two GCNConv to compute embeddings\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        #x : node feature matrix, edge_index : structure of the graph\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a05b40e",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ac895",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CoraGCN()\n",
    "model.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c0da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a23930c",
   "metadata": {},
   "source": [
    "<img src=\"../img/CoraGCN.png\" alt=\"nodepred_gcn\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4) #SGD, Adagrad\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    \n",
    "    ### NODE CLASSIFICATION ACTS HERE ###\n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    ### --- ###\n",
    "    \n",
    "    # Evaluation\n",
    "    train_correct = pred[data.train_mask] == data.y[data.train_mask]  # Check against ground-truth labels for train set.\n",
    "    train_acc = int(train_correct.sum()) / int(data.train_mask.sum())  # Derive ratio of correct predictions for train set.\n",
    "    test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels for test set.\n",
    "    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions for test set.\n",
    "    return train_acc, test_acc\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a2b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc,test_acc = test()\n",
    "print(f'Train Accuracy: {train_acc:.4f}\\nTest Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71df55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy()) #TSNE applied to node embeddings as numpy arrays\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "\n",
    "model.eval()\n",
    "out = model(data.x, data.edge_index)\n",
    "visualize(out, color=data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c52443",
   "metadata": {},
   "source": [
    "### Exercise 0 - GNN without G\n",
    "\n",
    "What is the effect of performing GCN forward computation using an empty edge index? First, try to answer without run the experiment. Then, try to reproduce your intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a2b53",
   "metadata": {},
   "source": [
    "### Exercise 1 - CoraGAT\n",
    "\n",
    "Write a GNN-based architecture for solving Node Classification task on Cora with the following requirements:\n",
    "- Use two MLP layers to pre-process BoW representations. The first MLP layer has 1433 input channels and 128 output channels. The second MLP layer has (128, 64) channels.\n",
    "- Use two graph attention network layers to obtain node embeddings. The graph attentional operator from the \"Graph Attention Networks\" is available in torch_geometric.nn as GATConv. The GAT layers have respectively (64,32) and (32,16) channels.\n",
    "- Use ReLu as activation function and apply dropout on the hidden layers.\n",
    "- Use a Linear layer to post-process the node embeddings and perform the decoder step. The Linear layer has (16,num_classes) channels.\n",
    "- Use a log softmax activation function on the output layer. Log softmax is available in torch.nn.functional.log_softmax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec1ec7",
   "metadata": {},
   "source": [
    "### Exercise 2 - Dive into evaluation\n",
    "\n",
    "Compare CoraGCN and CoraGAT on the node classification task.  \n",
    "Important: the node split masks as well as the weights' initialization into the GNN models must be the same.  \n",
    "Perform also this additional steps:\n",
    "\n",
    "- Conduct some hyperparameter optimization on Adam hypeparameters\n",
    "- Print train and test accuracy along the epochs\n",
    "- Print different evaluation metrics (e.g. confusion matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d7416e",
   "metadata": {},
   "source": [
    "### Link Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a3918",
   "metadata": {},
   "source": [
    "#### Link split and negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd08bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform random link split\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "link_split = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "train_link, val_link, test_link = link_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd61b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca37377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_label : 1 for closed link, 0 for open link\n",
    "# edge_label_index: edge_index + negative_sampling edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263e0bb",
   "metadata": {},
   "source": [
    "`RandomLinkSplit` performs split + negative sampling: this is perfect for static networks. Suppose you want to test your model in a future time interval... you do not need to perform a link split. How to perform negative sampling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e52d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "future_data = Planetoid(root='data/Planetoid', name='Cora')[0]\n",
    "\n",
    "#NEGATIVE SAMPLING\n",
    "future_neg_edge_index = negative_sampling(\n",
    "        edge_index=future_data.edge_index, #positive edges\n",
    "        num_nodes=future_data.num_nodes, # number of nodes\n",
    "        num_neg_samples=future_data.edge_index.size(1)) # number of neg_sample equal to number of pos_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb94269",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_neg_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ec9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edge index ok, edge_label concat, edge_label_index concat\n",
    "num_pos_edge = future_data.edge_index.size(1)\n",
    "future_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_pos_edge)]))\n",
    "future_data.edge_label_index = torch.cat([future_data.edge_index, future_neg_edge_index], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2715e4",
   "metadata": {},
   "source": [
    "#### GNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0af76",
   "metadata": {},
   "source": [
    "We can re-use the same GNN model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15033028",
   "metadata": {},
   "source": [
    "<img src=\"../img/CoraGCNLinkPre.png\" alt=\"linkpred_gcn\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad981518",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CoraGCN()\n",
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion =  torch.nn.BCEWithLogitsLoss() #change loss function\n",
    "\n",
    "def train_linkpre():\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(train_link.x, train_link.edge_index)  # Perform a single forward pass.\n",
    "    \n",
    "    ### LINK PREDICTION ACTS HERE ###\n",
    "    \n",
    "    out_src = out[train_link.edge_label_index[0]] #embedding src nodes\n",
    "    out_dst = out[train_link.edge_label_index[1]] #embedding dst nodes\n",
    "    \n",
    "    # LINK EMBEDDING #\n",
    "    # 1 - Dot Product\n",
    "    out_sim = out_src * out_dst #dotproduct\n",
    "    pred = torch.sum(out_sim, dim=-1)\n",
    "    \n",
    "    # 2 - Concatenation + linear function\n",
    "    #out_sim = torch.cat([out_src, out_dst], dim=-1)\n",
    "    #pred = torch.sum(out_sim,dim=-1)\n",
    "    \n",
    "    \n",
    "    loss = criterion(pred, train_link.edge_label.type_as(pred))  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss\n",
    "\n",
    "def test_linkpre(test_link):\n",
    "    model.eval()\n",
    "    out = model(test_link.x, test_link.edge_index)\n",
    "    \n",
    "    ### LINK PREDICTION ACTS HERE ###\n",
    "    \n",
    "    out_src = out[test_link.edge_label_index[0]] #embedding src nodes\n",
    "    out_dst = out[test_link.edge_label_index[1]] #embedding dst nodes\n",
    "    \n",
    "    # LINK EMBEDDING #\n",
    "    # 1 - Dot Product\n",
    "    out_sim = out_src * out_dst\n",
    "    h = torch.sum(out_sim, dim=-1)\n",
    "    \n",
    "    # 2 - Concatenation + linear function\n",
    "    #out_sim = torch.cat([out_src, out_dst], dim=-1)\n",
    "    #h = torch.sum(out_sim,dim=-1)\n",
    "    \n",
    "    pred_cont = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    \n",
    "    # EVALUATION\n",
    "    test_label = test_link.edge_label.cpu().detach().numpy() #retrieve test set labels\n",
    "    test_roc_score = roc_auc_score(test_label, pred_cont) #comput AUROC score for test set\n",
    "    \n",
    "    return test_roc_score\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train_linkpre()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73773cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_train = test_linkpre(train_link)\n",
    "roc_test = test_linkpre(test_link)\n",
    "print(f'Train AUROC: {roc_train:.4f}\\nTest AUROC: {roc_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66923a51",
   "metadata": {},
   "source": [
    "### Exercise 3 - HadamardMLP\n",
    "Actually, there are two popular solutions to perform the decoder step of link prediction tasks: the dot product and the HadamardMLP architecture. After theoretical and empirical analysis, [Wang et al. (2022)](https://arxiv.org/abs/2209.10100) find that the HadamardMLP decoders are generally more effective for LP.  \n",
    "\n",
    "Implement the HadamardMLP decoder into the CoraGCN architecture. The HadamardMLP consists of two steps:\n",
    "- Perform the hadamard product between the embeddings of nodes src and the embeddings of nodes dst.\n",
    "- Use a MLP layer to post-process the hadamard product.  \n",
    "\n",
    "Note that, for this task, you need to create a CoraGCNLP class that returns link prediction scores as the output of the forward method. Only in this way, the MLP layer parameters can be updated through the backpropagation steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
